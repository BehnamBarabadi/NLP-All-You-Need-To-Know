{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\behnam\\anaconda3\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (0.7.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (4.48.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy) (46.0.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (0.23)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (46.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.48.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2019.9.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\behnam\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.2.0)\n",
      "symbolic link created for C:\\Users\\Behnam\\Anaconda3\\lib\\site-packages\\spacy\\data\\en <<===>> C:\\Users\\Behnam\\Anaconda3\\lib\\site-packages\\en_core_web_sm\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "[+] Linking successful\n",
      "C:\\Users\\Behnam\\Anaconda3\\lib\\site-packages\\en_core_web_sm -->\n",
      "C:\\Users\\Behnam\\Anaconda3\\lib\\site-packages\\spacy\\data\\en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Behnam\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# download English corpus for spacy\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import datasets\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Sentiment Analysis Dataset\n",
    "Source: http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>neg</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID Sentiment SentimentSource  \\\n",
       "0       1       neg    Sentiment140   \n",
       "1       2       neg    Sentiment140   \n",
       "2       3       pos    Sentiment140   \n",
       "3       4       neg    Sentiment140   \n",
       "4       5       neg    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \n",
       "0                       is so sad for my APL frie...  \n",
       "1                     I missed the New Moon trail...  \n",
       "2                            omg its already 7:30 :O  \n",
       "3  .. Omgaga. Im sooo  im gunna CRy. I've been at...  \n",
       "4           i think mi bf is cheating on me!!!   ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('datasets/tweets/tweets.csv', error_bad_lines = False)\n",
    "\n",
    "tweets = tweets.head(50000)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe consists of 4 columns and we want to use only ‘Sentiment’ and ‘SentimentText’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                      SentimentText\n",
       "0       neg                       is so sad for my APL frie...\n",
       "1       neg                     I missed the New Moon trail...\n",
       "2       pos                            omg its already 7:30 :O\n",
       "3       neg  .. Omgaga. Im sooo  im gunna CRy. I've been at...\n",
       "4       neg           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets  = tweets.drop(columns = ['ItemID', 'SentimentSource'], axis = 1)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    26921\n",
       "neg    23079\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Labels')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "ax = sns.barplot(x=tweets.Sentiment.unique(), y=tweets.Sentiment.value_counts())\n",
    "\n",
    "ax.set(xlabel='Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's a binay text classification\n",
    "- Not an inbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(tweets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Sentiment                                      SentimentText\n",
       " 0           pos  @amyrenea omg so am I lol I fell asleep when i...\n",
       " 1           neg               @Adrienne_Bailon I want a shout out \n",
       " 2           neg  @Anonymousboy03 Plans for school stuff &amp; a...\n",
       " 3           neg  ... has hit a writer's block .. am loosing my ...\n",
       " 4           neg  ... trying to find people I know! I`m bored, i...\n",
       " ...         ...                                                ...\n",
       " 39995       pos   #robotpickuplines are so funny. check them out. \n",
       " 39996       pos  @annyo84 awh thankss.  yeah, i understand what...\n",
       " 39997       pos  @AmbiguityX ohh you're in twin cities?  i luv ...\n",
       " 39998       neg   Dinara lost again in Roland Garros. Why the S...\n",
       " 39999       pos  *yawn* fucking time zones shit. I'm really sic...\n",
       " \n",
       " [40000 rows x 2 columns],\n",
       "      Sentiment                                      SentimentText\n",
       " 0          pos  @aimeesays aww i hope it does fly by because J...\n",
       " 1          neg  #dontyouhate when you JUST painted yur nails a...\n",
       " 2          neg  - @EvertB which one? http://bit.ly/10o8LW, htt...\n",
       " 3          pos  *shriek* Bee almost flew here from window. I'm...\n",
       " 4          pos  @Alyssa_Milano granted if we lose it is to a w...\n",
       " ...        ...                                                ...\n",
       " 9995       neg  @aisforamylynn you're a badass for having a ba...\n",
       " 9996       pos  @acts_rox  I'm not particular about it being f...\n",
       " 9997       pos                     @@j311stp and the same to you!\n",
       " 9998       pos  .@nanere Sheila I heart you!! That &quot;Holly...\n",
       " 9999       neg   not the same without a goodnight....hm. Wish ...\n",
       " \n",
       " [10000 rows x 2 columns])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True), test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>39087</td>\n",
       "      <td>pos</td>\n",
       "      <td>@amyrenea omg so am I lol I fell asleep when i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30893</td>\n",
       "      <td>neg</td>\n",
       "      <td>@Adrienne_Bailon I want a shout out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45278</td>\n",
       "      <td>neg</td>\n",
       "      <td>@Anonymousboy03 Plans for school stuff &amp;amp; a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16398</td>\n",
       "      <td>neg</td>\n",
       "      <td>... has hit a writer's block .. am loosing my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13653</td>\n",
       "      <td>neg</td>\n",
       "      <td>... trying to find people I know! I`m bored, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                      SentimentText\n",
       "39087       pos  @amyrenea omg so am I lol I fell asleep when i...\n",
       "30893       neg               @Adrienne_Bailon I want a shout out \n",
       "45278       neg  @Anonymousboy03 Plans for school stuff &amp; a...\n",
       "16398       neg  ... has hit a writer's block .. am loosing my ...\n",
       "13653       neg  ... trying to find people I know! I`m bored, i..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 2), (10000, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('datasets/tweets/train_tweets.csv', index=False)\n",
    "test.to_csv('datasets/tweets/test_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is SSD\n",
      " Volume Serial Number is F6B3-93A4\n",
      "\n",
      " Directory of D:\\Google Drive\\Jupyter Notebooks\\Pluralsight - NLP with PyTorch\\datasets\\tweets\n",
      "\n",
      "07/31/2020  10:53 PM    <DIR>          .\n",
      "07/31/2020  10:53 PM    <DIR>          ..\n",
      "08/08/2020  07:33 PM           828,626 test_tweets.csv\n",
      "08/08/2020  07:33 PM         3,344,576 train_tweets.csv\n",
      "06/14/2019  03:48 AM         5,111,924 tweets.csv\n",
      "               3 File(s)      9,285,126 bytes\n",
      "               2 Dir(s)  923,120,570,368 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir datasets\\tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining a funtion to clean the tweets by removing non alphanumeric character and links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_clean(text):\n",
    "    \n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text) \n",
    "    text = re.sub(r'https?:/\\/\\S+', ' ', text) \n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  The tweet column (‘SentimentText’) needs processing and tokenization, so that it can be converted into indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp is a spacy object\n",
    "# we only want the tokenizer so we disable 'parser', 'tagger' and 'ner'\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def tokenizer(s): \n",
    "    # 1st clean s, then parse it with nlp and last, convert it to lower-case\n",
    "    return [w.text.lower() for w in nlp(tweet_clean(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operates on text and tolenize it using the tokenizer function we defined above\n",
    "TEXT = torchtext.data.Field(tokenize = tokenizer)\n",
    "\n",
    "# operates on labels and convert them to numeric values\n",
    "LABEL = torchtext.data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafields = [('Sentiment', LABEL), ('SentimentText', TEXT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create torchtext dataset,TabularDataset which is specially designed to read csv and tsv files and process them. It is a wrapper around pytorch Dataset with additional features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = torchtext.data.TabularDataset.splits(path = 'datasets/tweets/', \n",
    "                                                train = 'train_tweets.csv',\n",
    "                                                test = 'test_tweets.csv',    \n",
    "                                                format = 'csv',\n",
    "                                                skip_header = True,\n",
    "                                                fields = datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of testing examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(trn)}')\n",
    "print(f'Number of testing examples: {len(tst)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `vars()` function returns the `__dict__` attribute of the given object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentiment': 'pos',\n",
       " 'SentimentText': ['amyrenea',\n",
       "  'omg',\n",
       "  'so',\n",
       "  'am',\n",
       "  'i',\n",
       "  'lol',\n",
       "  'i',\n",
       "  'fell',\n",
       "  'asleep',\n",
       "  'when',\n",
       "  'it',\n",
       "  'was',\n",
       "  'on',\n",
       "  'last',\n",
       "  'night',\n",
       "  'so',\n",
       "  'now',\n",
       "  'i',\n",
       "  'get',\n",
       "  'to',\n",
       "  'finish',\n",
       "  'it']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a dict shape object which key is the label and value is a list of tokenized words in lowercase\n",
    "vars(trn.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aimeesays'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st word in the value list\n",
    "vars(tst.examples[0])['SentimentText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentiment': 'pos',\n",
       " 'SentimentText': ['aimeesays',\n",
       "  'aww',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'it',\n",
       "  'does',\n",
       "  'fly',\n",
       "  'by',\n",
       "  'because',\n",
       "  'jt',\n",
       "  'episodes',\n",
       "  'are',\n",
       "  'usually',\n",
       "  'really',\n",
       "  'good',\n",
       "  'and',\n",
       "  'it',\n",
       "  's',\n",
       "  'early',\n",
       "  'but',\n",
       "  'so',\n",
       "  'far',\n",
       "  'this',\n",
       "  'ep',\n",
       "  'hassn',\n",
       "  't',\n",
       "  'disappointed']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(tst.examples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pretrained word vectors and build vocabulary\n",
    "Now, instead of having our word embeddings initialized randomly, they are initialized with these pre-trained vectors. We get these vectors simply by specifying which vectors we want and passing it as an argument to build_vocab. TorchText handles downloading the vectors and associating them with the correct words in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_vocab creates a vocab of the input data in this case, training data\n",
    "TEXT.build_vocab(trn, max_size=25000, # only top 25,000 word in vocab = size of feature vector \n",
    "                 vectors=\"glove.6B.100d\", # index position of words in vocab comes from GloVe\n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "                # unknown words in the sentence initialize using normal distribution and not 0\n",
    "\n",
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 25644), ('the', 12219), ('to', 12111), ('you', 10723), ('a', 9197), ('it', 8440), ('and', 6889), ('my', 6208), ('quot', 5582), ('s', 5565), ('that', 5306), ('is', 5203), ('for', 4971), ('in', 4852), ('t', 4844), ('m', 4683), ('me', 4588), ('of', 4331), ('on', 3918), ('have', 3752), ('so', 3612), ('but', 3506), ('be', 2932), ('not', 2887), ('was', 2775), ('just', 2724), ('can', 2523), ('do', 2418), ('are', 2351), ('your', 2320), ('with', 2269), ('good', 2203), ('like', 2173), ('at', 2131), ('no', 2119), ('this', 2094), ('all', 2069), ('up', 2066), ('now', 2063), ('get', 2044), ('we', 1988), ('u', 1890), ('love', 1885), ('lol', 1864), ('too', 1826), ('what', 1760), ('out', 1742), ('know', 1664), ('nt', 1608), ('amp', 1539)]\n"
     ]
    }
   ],
   "source": [
    "# most common 50 words in vocab with their indices\n",
    "print(TEXT.vocab.freqs.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25002"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab['i']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The additional 2 words in `TEXT.vocab` are:\n",
    "- `pad` : to fill empty spaces for each example\n",
    "- `unk`: to show words which are not present in train vocab but are in test vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'i', 'the', 'to', 'you', 'a', 'it', 'and', 'my']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'pos': 0, 'neg': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data in batches\n",
    "For data with variable length sentences torchtext provides `BucketIterator()` dataloader which is wrapper around pytorch Dataloader. \n",
    "- `BucketIterator()` clump to gether sentences of the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets.SentimentText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
    "                                (trn, tst),\n",
    "                                batch_size = 64,\n",
    "                                #sort based on the length of the SentimentText\n",
    "                                sort_key=lambda x: len(x.SentimentText), \n",
    "                                sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll be using a different RNN architecture called a Long Short-Term Memory (LSTM).\n",
    "\n",
    "<b>torch.nn.embedding</b> -A simple lookup table that stores embeddings of a fixed dictionary and size.This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.\n",
    "\n",
    "\n",
    "<b>LSTM</b> - Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.\n",
    "\n",
    "<b>bidirectional</b> - an RNN processing the words in the sentence from the first to the last (a forward RNN), we have a second RNN processing the words in the sentence from the last to the first (a backward RNN). At time step $t$, the forward RNN is processing word $x_t$, and the backward RNN is processing word $x_{T-t+1}$.\n",
    "\n",
    "\n",
    "<b>Dropout</b> - it works by randomly dropping out (setting to 0) neurons in a layer during a forward pass. The probability that each neuron is dropped out is set by a hyperparameter and each neuron with dropout applied is considered indepenently.This helps in regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Input**\n",
    "torch.nn.RNN has two inputs : `input` and `h_0` ie. the input sequence and the hidden-layer at t=0. If we don't initialize the hidden layer, it will be auto-initiliased by PyTorch to be all zeros.\n",
    "- input is the sequence which is fed into the network. It should be of size `(seq_len, batch, input_size)`. If `batch_first=True`, the input size is `(batch, seq_len, input_size)`.\n",
    "- h_0 is the initial hidden state of the network. It is of the size `(num_layers * num_directions, batch, input_size)` where num_layers is the number of stacked RNNs. num_directions = 2 for bidirectional RNNs and 1 otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Output**\n",
    "torch.nn.RNN has two outputs - `out` and `hidden`.\n",
    "`out` is the output of the RNN from all timesteps from the last RNN layer. It is of the size `(seq_len, batch, num_directions * hidden_size)`. If `batch_first=True`, the output size is (`batch, seq_len, num_directions * hidden_size)`.\n",
    "`h_n` is the hidden value from the last time-step of all RNN layers. It is of the size `(num_layers * num_directions, batch, hidden_size)`. `h_n` is unaffected by `batch_first=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"Images/RNN architecture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     `output` is the output of the RNN from all timesteps from the last RNN layer.\n",
    " ###    `h_n` is the hidden-state value from the last time-step of all RNN layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention!\n",
    "- For multy-layer RNN, the input to the fc layer is concatanation of 2 hidden states\n",
    "\n",
    "`torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n",
    "                 output_dim, n_layers, bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # input is in form of one-hot encoed converted to embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, \n",
    "                           bidirectional = bidirectional, dropout=dropout)\n",
    "        \n",
    "        #multiply by 2 is because of bidirectionality, 2 hidden state in forward and reverse direction\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #print(\"text\", text.shape) = (seq_length, 20) 2o is hidden dim\n",
    "        \n",
    "        # 1st convert input text into corresponding embedding and then apply dropout\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        #print(\"embedded\", embedded.shape) = (seq_length, 64, 20)\n",
    "        \n",
    "        # 2 hidden state from forward and backward RNN\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        # print(\"output\", output.shape = (seq_length, 64, 40)\n",
    "        # print(\"hidden\", hidden.shape ) = (4, 64, 20)\n",
    "        \n",
    "        # concatenate 2 hidden states into the final hidden state\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        # print(\"hidden\", hidden.shape) is (64, 40)\n",
    "        \n",
    "        # print('last', hidden.squeeze(0).shape) is (64, 40)\n",
    "        # print(self.fc(hidden.squeeze(0)).shape) is (64, 1)                                      \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the pre-trained vectors can be loaded into the model, the EMBEDDING_DIM must be equal to that of the pre-trained GloVe vectors loaded earlier.\n",
    "\n",
    "We get our pad token index from the vocabulary, getting the actual string representing the pad token from the field's pad_token attribute, which is pad by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(TEXT.vocab) # 25,002\n",
    "\n",
    "embedding_dim = 100 # corresponds to GloVe embedding (vectors = \"glove.6B.100d\")\n",
    "\n",
    "hidden_dim = 20 # simillar t0 20 neurons in RNN layer\n",
    "output_dim = 1\n",
    "\n",
    "n_layers = 2 # 2 layers\n",
    "bidirectional = True\n",
    "\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_dim, \n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            output_dim, \n",
    "            n_layers, \n",
    "            bidirectional, \n",
    "            dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(25002, 100)\n",
       "  (rnn): GRU(100, 20, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=40, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve the embeddings from the field's vocab, and check they're the correct size, [vocab size, embedding dim]\n",
    "- 25,002 most frequent words in our vocab\n",
    "- each embedding has the dimensionality of 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then replace the initial weights of the embedding layer with the pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3744, -0.9346, -0.2560,  ..., -1.0419, -1.2345, -0.5804],\n",
       "        [ 0.6945,  1.8962, -0.1613,  ..., -2.2072, -2.3925, -1.2877],\n",
       "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
       "        ...,\n",
       "        [-1.9859,  0.6130, -0.2060,  ...,  0.2449,  0.2522, -0.9568],\n",
       "        [-1.1472, -0.5669,  0.8012,  ..., -0.4997,  0.1264, -0.4542],\n",
       "        [ 0.8382, -0.2901, -0.6670,  ..., -0.6708,  1.2218, -0.7844]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting `unk` and `pad` tokens to zero, means they have no value in understanding the sentiment\n",
    "As our < unk > and < pad > token aren't in the pre-trained vocabulary they have been initialized using unk_init (an $\\mathcal{N}(0,1)$ distribution) when building our vocab. It is preferable to initialize them both to all zeros to explicitly tell our model that, initially, they are irrelevant for determining sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unk_idx:  0 \n",
      "pad_idx:  1\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
      "        ...,\n",
      "        [-1.9859,  0.6130, -0.2060,  ...,  0.2449,  0.2522, -0.9568],\n",
      "        [-1.1472, -0.5669,  0.8012,  ..., -0.4997,  0.1264, -0.4542],\n",
      "        [ 0.8382, -0.2901, -0.6670,  ..., -0.6708,  1.2218, -0.7844]])\n"
     ]
    }
   ],
   "source": [
    "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "print('unk_idx: ', unk_idx, '\\npad_idx: ', pad_idx )\n",
    "\n",
    "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
    "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see above,  the first 2 vectors are zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the embedding of a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8300"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['ufc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5941, -0.2980,  0.4845, -1.0484, -0.1234, -0.7606, -0.3824,  0.0547,\n",
       "        -0.5145,  0.4720,  1.1300, -0.6752,  0.5322, -1.4753,  0.7268, -1.0578,\n",
       "         0.7085, -0.0226,  0.6492, -0.5271,  0.5378, -1.3725,  0.6805,  0.3684,\n",
       "         0.3946,  0.3264,  0.7379,  0.3787,  1.4240,  0.8743, -0.9630, -0.2236,\n",
       "        -0.2297,  0.4366,  0.1340,  0.7371, -0.6388,  0.0802, -0.4933,  0.5903,\n",
       "        -0.1161,  0.1407,  0.2577, -0.6073,  0.1068, -0.4910, -0.5081,  0.0193,\n",
       "        -0.8991,  0.5141, -0.6505,  0.0244, -0.4841,  0.4380,  1.1311, -0.9572,\n",
       "         0.2540,  0.0479, -1.1566,  0.1825,  0.1217, -0.2933, -0.9783,  0.0429,\n",
       "        -0.1324, -1.1153, -0.1110, -0.4143, -0.7511,  0.3366,  0.0281, -0.4760,\n",
       "        -1.0994,  1.0847,  0.1064,  0.0838, -0.3123,  0.3206, -0.6370,  0.4812,\n",
       "         0.0880, -0.9473,  0.8987, -0.4394,  0.5618, -0.5753, -0.1427,  0.1543,\n",
       "         0.3749, -0.0160, -0.0100, -0.1311, -0.1834,  1.4182, -0.0115, -0.5173,\n",
       "         0.2775,  1.1060,  0.6482, -0.1146])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data[TEXT.vocab.stoi['ufc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model\n",
    "\n",
    "We use Adam optimizer and loss function is BCEWithLogitLoss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # this loss function is for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We define a function for training our model\n",
    "as we are now using dropout, we must remember to use model.train() to ensure the dropout is \"turned on\" while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch.SentimentText = batch.SentimentText.to(device)\n",
    "        batch.Sentiment = batch.Sentiment.to(device)\n",
    "        \n",
    "        # output of the model is: (batch_size, 1) and we get rid of 1 with sueeze(dim=1)\n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "        \n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.Sentiment).float() \n",
    "        \n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.545 | Train Acc: 73.10% |\n",
      "| Epoch: 02 | Train Loss: 0.498 | Train Acc: 76.47% |\n",
      "| Epoch: 03 | Train Loss: 0.469 | Train Acc: 78.03% |\n",
      "| Epoch: 04 | Train Loss: 0.445 | Train Acc: 79.47% |\n",
      "| Epoch: 05 | Train Loss: 0.428 | Train Acc: 80.66% |\n",
      "| Epoch: 06 | Train Loss: 0.411 | Train Acc: 81.75% |\n",
      "| Epoch: 07 | Train Loss: 0.392 | Train Acc: 82.61% |\n",
      "| Epoch: 08 | Train Loss: 0.380 | Train Acc: 83.32% |\n",
      "| Epoch: 09 | Train Loss: 0.362 | Train Acc: 84.09% |\n",
      "| Epoch: 10 | Train Loss: 0.351 | Train Acc: 84.90% |\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "     \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in test_iterator:\n",
    "        \n",
    "        batch.SentimentText = batch.SentimentText.to(device)\n",
    "        batch.Sentiment = batch.Sentiment.to(device)\n",
    "\n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "\n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.Sentiment).float() \n",
    "        \n",
    "        acc = correct.sum()/len(correct)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "test_loss = epoch_loss / len(test_iterator)\n",
    "test_acc = epoch_acc / len(test_iterator)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    #initialize every epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    #deactivating dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    #deactivates autograd\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "        \n",
    "            #retrieve text and no. of words\n",
    "            batch.SentimentText = batch.SentimentText.to(device)\n",
    "            batch.Sentiment = batch.Sentiment.to(device)\n",
    "#             text = text.to(device)\n",
    "#             batch.label = batch.label.to(device)\n",
    "        \n",
    "            predictions = model(batch.SentimentText).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions, batch.Sentiment)\n",
    "\n",
    "            \n",
    "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "            correct = (rounded_preds == batch.Sentiment).float() \n",
    "            \n",
    "            acc = correct.sum() / len(correct)\n",
    "            \n",
    "            #keep track of loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\tTrain Loss: 0.149 | Train Acc: 94.22%\n",
      "\t Val. Loss: 0.791 |  Val. Acc: 74.14%\n",
      "Epoch: 1\n",
      "\tTrain Loss: 0.144 | Train Acc: 94.27%\n",
      "\t Val. Loss: 0.792 |  Val. Acc: 73.99%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    #train the model\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_loss, valid_acc = evaluate(model, test_iterator, criterion)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(25002, 100)\n",
       "  (rnn): GRU(100, 20, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=40, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(input_dim, \n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            output_dim, \n",
    "            n_layers, \n",
    "            bidirectional, \n",
    "            dropout)\n",
    "model.load_state_dict(torch.load('model_gru_GloVe.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(25002, 100)\n",
      "  (rnn): GRU(100, 20, num_layers=2, dropout=0.5, bidirectional=True)\n",
      "  (fc): Linear(in_features=40, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input\n",
    "We can now use our model to predict the sentiment of any sentence we give it.As it has been trained on tweets, the sentences provided should in a positive or a negative context.\n",
    "\n",
    "We are expecting tweets with a negative sentiment to return a value close to 1 and positive tweets to return a value close to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I hate that show' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'hate', 'that', 'show']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the sentence using spacy tokenizer created earlier\n",
    "tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index of word in the GloVe vocab \n",
    "TEXT.vocab.stoi['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 185, 12, 165]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, 185,  12, 165])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting indices to tensor\n",
    "tensor = torch.LongTensor(indexed)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding another dimension because our model expects it\n",
    "tensor = tensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor.to(device)\n",
    "prediction = torch.sigmoid(model(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'pos': 0, 'neg': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7903881669044495"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this prediction is near 1 so it belongs to negative\n"
     ]
    }
   ],
   "source": [
    "print(\"this prediction is near 1 so it belongs to negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =[ \"do you hate ufc or you love it?\",\n",
    "\"That movie was really nice\",\n",
    "\"I hate that show but recently it has been quite good\",\n",
    "\"That movie was decent but kind of fizzled out towards the end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_label(sentences):\n",
    "    for sentence in sentences:\n",
    "        tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "        indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "        tensor = torch.LongTensor(indexed).unsqueeze(1)\n",
    "        tensor = tensor.to(device)\n",
    "        prediction = torch.sigmoid(model(tensor))        \n",
    "        if np.round(prediction.item()) == 1:\n",
    "            print(sentence,\": negative\", np.around(prediction.item(), 2))\n",
    "        else:\n",
    "            print(sentence,\": positive\", np.around(prediction.item(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you hate ufc or you love it? : negative 0.93\n",
      "That movie was really nice : positive 0.08\n",
      "I hate that show but recently it has been quite good : negative 0.65\n",
      "That movie was decent but kind of fizzled out towards the end : positive 0.05\n"
     ]
    }
   ],
   "source": [
    "predict_label(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
